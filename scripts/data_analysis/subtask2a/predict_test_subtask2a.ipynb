{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Subtask 2a - Test Data Prediction with Ensemble\n",
        "\n",
        "This notebook runs the prediction pipeline for SemEval 2026 Task 2 Subtask 2a.\n",
        "It loads 3 trained models, generates predictions, and creates a weighted ensemble submission."
      ],
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "setup_drive"
      },
      "outputs": [],
      "source": [
        "# @title 1. Setup & Mount Drive\n",
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Install dependencies\n",
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "config"
      },
      "outputs": [],
      "source": [
        "# @title 2. Configuration\n",
        "# Adjust these paths to match your Google Drive structure\n",
        "BASE_PATH = '/content/drive/MyDrive/Deep-Learning-project-SemEval-2026-Task-2'  # <--- CHANGE THIS\n",
        "\n",
        "MODEL_DIR = os.path.join(BASE_PATH, 'models')\n",
        "RESULTS_DIR = os.path.join(BASE_PATH, 'results/subtask2a')\n",
        "TEST_DATA_PATH = os.path.join(BASE_PATH, 'test_subtask2a.csv')\n",
        "\n",
        "MODEL_PATHS = {\n",
        "    'seed42': os.path.join(MODEL_DIR, 'subtask2a_seed42_best.pt'),\n",
        "    'seed123': os.path.join(MODEL_DIR, 'subtask2a_seed123_best.pt'),\n",
        "    'seed777': os.path.join(MODEL_DIR, 'subtask2a_seed777_best.pt')\n",
        "}\n",
        "\n",
        "ENSEMBLE_WEIGHTS_PATH = os.path.join(RESULTS_DIR, 'ensemble_results.json')\n",
        "\n",
        "# Parameters\n",
        "SEQ_LENGTH = 128\n",
        "BATCH_SIZE = 16\n",
        "\n",
        "print(f'Base Path: {BASE_PATH}')\n",
        "print(f'Model Dir: {MODEL_DIR}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "imports"
      },
      "outputs": [],
      "source": [
        "# @title 3. Imports & Device Setup\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "from tqdm.notebook import tqdm\n",
        "import json\n",
        "import re\n",
        "\n",
        "# Device setup\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f'Using device: {device}')\n",
        "if torch.cuda.is_available():\n",
        "    print(f'GPU: {torch.cuda.get_device_name(0)}')\n",
        "    print(f'Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "helper_functions"
      },
      "outputs": [],
      "source": [
        "# @title 4. Helper Functions\n",
        "\n",
        "def extract_text_features(text):\n",
        "    \"\"\"Extract text-based features from a single text\"\"\"\n",
        "    # Length features\n",
        "    text_length = len(text)\n",
        "    word_count = len(text.split())\n",
        "    avg_word_length = sum(len(word) for word in text.split()) / max(word_count, 1)\n",
        "\n",
        "    # Sentence features\n",
        "    sentence_count = len([s for s in text.split('.') if s.strip()])\n",
        "    avg_sentence_length = word_count / max(sentence_count, 1)\n",
        "\n",
        "    # Punctuation features\n",
        "    exclamation_count = text.count('!')\n",
        "    question_count = text.count('?')\n",
        "    comma_count = text.count(',')\n",
        "    period_count = text.count('.')\n",
        "\n",
        "    # Case features\n",
        "    upper_count = sum(1 for c in text if c.isupper())\n",
        "    upper_ratio = upper_count / max(len(text), 1)\n",
        "\n",
        "    # Emotion word counts (simple)\n",
        "    positive_words = ['good', 'great', 'happy', 'love', 'excellent', 'wonderful', 'fantastic']\n",
        "    negative_words = ['bad', 'sad', 'terrible', 'hate', 'awful', 'horrible', 'miserable']\n",
        "\n",
        "    text_lower = text.lower()\n",
        "    positive_count = sum(text_lower.count(word) for word in positive_words)\n",
        "    negative_count = sum(text_lower.count(word) for word in negative_words)\n",
        "\n",
        "    # Digit features\n",
        "    digit_count = sum(1 for c in text if c.isdigit())\n",
        "\n",
        "    # Special char features\n",
        "    special_char_count = len(re.findall(r'[^a-zA-Z0-9\\s]', text))\n",
        "\n",
        "    return [\n",
        "        text_length, word_count, avg_word_length,\n",
        "        sentence_count, avg_sentence_length,\n",
        "        exclamation_count, question_count, comma_count, period_count,\n",
        "        upper_count, upper_ratio,\n",
        "        positive_count, negative_count,\n",
        "        digit_count, special_char_count\n",
        "    ]\n",
        "\n",
        "def preprocess_test_data(df):\n",
        "    \"\"\"\n",
        "    Preprocess test data and create lag features\n",
        "    \"\"\"\n",
        "    print('\\n=== Preprocessing Test Data ===')\n",
        "\n",
        "    # Sort by user and timestamp\n",
        "    df = df.sort_values(['user_id', 'timestamp']).reset_index(drop=True)\n",
        "\n",
        "    # Initialize feature columns\n",
        "    df['lag_1_valence'] = 0.0\n",
        "    df['lag_1_arousal'] = 0.0\n",
        "    df['lag_2_valence'] = 0.0\n",
        "    df['lag_2_arousal'] = 0.0\n",
        "    df['lag_mean_valence'] = 0.0\n",
        "\n",
        "    # User statistics\n",
        "    user_stats_cols = []\n",
        "    if 'valence' in df.columns and 'arousal' in df.columns:\n",
        "        user_stats = df.groupby('user_id').agg({\n",
        "            'valence': ['mean', 'std', 'min', 'max', 'median'],\n",
        "            'arousal': ['mean', 'std', 'min', 'max', 'median'],\n",
        "            'text': 'count'\n",
        "        }).reset_index()\n",
        "\n",
        "        user_stats.columns = ['user_id',\n",
        "            'user_valence_mean', 'user_valence_std', 'user_valence_min', 'user_valence_max', 'user_valence_median',\n",
        "            'user_arousal_mean', 'user_arousal_std', 'user_arousal_min', 'user_arousal_max', 'user_arousal_median',\n",
        "            'user_text_count'\n",
        "        ]\n",
        "\n",
        "        # Fill NaN std with 0\n",
        "        user_stats['user_valence_std'] = user_stats['user_valence_std'].fillna(0)\n",
        "        user_stats['user_arousal_std'] = user_stats['user_arousal_std'].fillna(0)\n",
        "\n",
        "        # Normalize user_text_count\n",
        "        user_stats['user_text_count_norm'] = user_stats['user_text_count'] / user_stats['user_text_count'].max()\n",
        "\n",
        "        df = df.merge(user_stats, on='user_id', how='left')\n",
        "\n",
        "        user_stats_cols = ['user_valence_mean', 'user_valence_std', 'user_valence_min', 'user_valence_max', 'user_valence_median',\n",
        "                          'user_arousal_mean', 'user_arousal_std', 'user_arousal_min', 'user_arousal_max', 'user_arousal_median',\n",
        "                          'user_text_count', 'user_text_count_norm']\n",
        "\n",
        "        # Create lag features within each user\n",
        "        for user_id, group in df.groupby('user_id'):\n",
        "            indices = group.index\n",
        "\n",
        "            for i, idx in enumerate(indices):\n",
        "                if i >= 1:\n",
        "                    df.loc[idx, 'lag_1_valence'] = df.loc[indices[i-1], 'valence']\n",
        "                    df.loc[idx, 'lag_1_arousal'] = df.loc[indices[i-1], 'arousal']\n",
        "\n",
        "                if i >= 2:\n",
        "                    df.loc[idx, 'lag_2_valence'] = df.loc[indices[i-2], 'valence']\n",
        "                    df.loc[idx, 'lag_2_arousal'] = df.loc[indices[i-2], 'arousal']\n",
        "\n",
        "                if i >= 1:\n",
        "                    df.loc[idx, 'lag_mean_valence'] = df.loc[indices[:i], 'valence'].mean()\n",
        "    else:\n",
        "        # If no valence/arousal in test data, use zeros\n",
        "        print('⚠️ No valence/arousal in test data, using zero features')\n",
        "        user_stats_cols = []\n",
        "\n",
        "        # Create dummy user stats\n",
        "        for col in ['user_valence_mean', 'user_valence_std', 'user_valence_min', 'user_valence_max', 'user_valence_median',\n",
        "                    'user_arousal_mean', 'user_arousal_std', 'user_arousal_min', 'user_arousal_max', 'user_arousal_median',\n",
        "                    'user_text_count', 'user_text_count_norm']:\n",
        "            df[col] = 0.0\n",
        "            user_stats_cols.append(col)\n",
        "\n",
        "    # Extract text features\n",
        "    print('Extracting text features...')\n",
        "    text_features_list = []\n",
        "    for text in tqdm(df['text'], desc='Text features'):\n",
        "        text_features_list.append(extract_text_features(text))\n",
        "\n",
        "    text_features = np.array(text_features_list)\n",
        "    text_feature_cols = [f'text_feat_{i}' for i in range(text_features.shape[1])]\n",
        "\n",
        "    for i, col in enumerate(text_feature_cols):\n",
        "        df[col] = text_features[:, i]\n",
        "\n",
        "    print(f'✓ Created {len(text_feature_cols)} text features')\n",
        "    print(f'✓ Created 5 lag features')\n",
        "    print(f'✓ Created {len(user_stats_cols)} user statistics')\n",
        "\n",
        "    return df, user_stats_cols, text_feature_cols"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dataset_class"
      },
      "outputs": [],
      "source": [
        "# @title 5. Dataset Class\n",
        "\n",
        "class TestEmotionDataset(Dataset):\n",
        "    \"\"\"Dataset for test data prediction\"\"\"\n",
        "\n",
        "    def __init__(self, df, tokenizer, seq_length, user_stats_cols, text_feature_cols):\n",
        "        self.df = df.reset_index(drop=True)\n",
        "        self.tokenizer = tokenizer\n",
        "        self.seq_length = seq_length\n",
        "        self.user_stats_cols = user_stats_cols\n",
        "        self.text_feature_cols = text_feature_cols\n",
        "\n",
        "        # User mapping\n",
        "        unique_users = df['user_id'].unique()\n",
        "        self.user_to_idx = {user_id: idx for idx, user_id in enumerate(unique_users)}\n",
        "        self.num_users = len(unique_users)\n",
        "\n",
        "        print(f'Test dataset: {len(self.df)} samples, {self.num_users} users')\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "\n",
        "        # Tokenize text\n",
        "        encoding = self.tokenizer(\n",
        "            row['text'],\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.seq_length,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "\n",
        "        # User index\n",
        "        user_idx = self.user_to_idx[row['user_id']]\n",
        "\n",
        "        # Temporal features (lag features)\n",
        "        temporal_features = torch.tensor([\n",
        "            row['lag_1_valence'], row['lag_1_arousal'],\n",
        "            row['lag_2_valence'], row['lag_2_arousal'],\n",
        "            row['lag_mean_valence']\n",
        "        ], dtype=torch.float32)\n",
        "\n",
        "        # User statistics\n",
        "        user_stats = torch.tensor([row[col] for col in self.user_stats_cols], dtype=torch.float32)\n",
        "\n",
        "        # Text features\n",
        "        text_features = torch.tensor([row[col] for col in self.text_feature_cols], dtype=torch.float32)\n",
        "\n",
        "        return {\n",
        "            'input_ids': encoding['input_ids'].squeeze(0),\n",
        "            'attention_mask': encoding['attention_mask'].squeeze(0),\n",
        "            'user_idx': torch.tensor(user_idx, dtype=torch.long),\n",
        "            'temporal_features': temporal_features,\n",
        "            'user_stats': user_stats,\n",
        "            'text_features': text_features,\n",
        "            'user_id': row['user_id']  # Keep for submission\n",
        "        }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "model_class"
      },
      "outputs": [],
      "source": [
        "# @title 6. Model Architecture\n",
        "\n",
        "class FinalEmotionModel(nn.Module):\n",
        "    \"\"\"\n",
        "    RoBERTa + BiLSTM + Multi-Head Attention + Dual-Head Loss\n",
        "    \"\"\"\n",
        "    def __init__(self, num_users, user_emb_dim=64, lstm_hidden=256, lstm_layers=2,\n",
        "                 attention_heads=8, dropout=0.3):\n",
        "        super().__init__()\n",
        "\n",
        "        # RoBERTa encoder\n",
        "        self.roberta = AutoModel.from_pretrained('roberta-base')\n",
        "        roberta_dim = 768\n",
        "\n",
        "        # User embeddings\n",
        "        self.user_embedding = nn.Embedding(num_users, user_emb_dim)\n",
        "\n",
        "        # BiLSTM\n",
        "        self.lstm = nn.LSTM(\n",
        "            roberta_dim,\n",
        "            lstm_hidden,\n",
        "            num_layers=lstm_layers,\n",
        "            batch_first=True,\n",
        "            bidirectional=True,\n",
        "            dropout=dropout if lstm_layers > 1 else 0\n",
        "        )\n",
        "\n",
        "        lstm_output_dim = lstm_hidden * 2  # Bidirectional\n",
        "\n",
        "        # Multi-head attention\n",
        "        self.attention = nn.MultiheadAttention(\n",
        "            embed_dim=lstm_output_dim,\n",
        "            num_heads=attention_heads,\n",
        "            dropout=dropout,\n",
        "            batch_first=True\n",
        "        )\n",
        "\n",
        "        # Feature dimensions\n",
        "        temporal_dim = 5  # lag features\n",
        "        user_stats_dim = 12  # user statistics\n",
        "        text_features_dim = 15  # text features\n",
        "\n",
        "        combined_dim = lstm_output_dim + user_emb_dim + temporal_dim + user_stats_dim + text_features_dim\n",
        "\n",
        "        # Dual-head output layers\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "        self.valence_head = nn.Sequential(\n",
        "            nn.Linear(combined_dim, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(256, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(128, 1)\n",
        "        )\n",
        "\n",
        "        self.arousal_head = nn.Sequential(\n",
        "            nn.Linear(combined_dim, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(256, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(128, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, user_idx, temporal_features, user_stats, text_features):\n",
        "        # RoBERTa encoding\n",
        "        roberta_output = self.roberta(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        sequence_output = roberta_output.last_hidden_state  # (batch, seq_len, 768)\n",
        "\n",
        "        # BiLSTM\n",
        "        lstm_output, _ = self.lstm(sequence_output)  # (batch, seq_len, lstm_hidden*2)\n",
        "\n",
        "        # Multi-head attention\n",
        "        attn_output, _ = self.attention(lstm_output, lstm_output, lstm_output)  # (batch, seq_len, lstm_hidden*2)\n",
        "\n",
        "        # Global average pooling\n",
        "        pooled_output = torch.mean(attn_output, dim=1)  # (batch, lstm_hidden*2)\n",
        "\n",
        "        # User embeddings\n",
        "        user_emb = self.user_embedding(user_idx)  # (batch, user_emb_dim)\n",
        "\n",
        "        # Concatenate all features\n",
        "        combined = torch.cat([\n",
        "            pooled_output,\n",
        "            user_emb,\n",
        "            temporal_features,\n",
        "            user_stats,\n",
        "            text_features\n",
        "        ], dim=1)\n",
        "\n",
        "        combined = self.dropout(combined)\n",
        "\n",
        "        # Dual-head predictions\n",
        "        valence_pred = self.valence_head(combined).squeeze(-1)\n",
        "        arousal_pred = self.arousal_head(combined).squeeze(-1)\n",
        "\n",
        "        return valence_pred, arousal_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "execution"
      },
      "outputs": [],
      "source": [
        "# @title 7. Run Prediction\n",
        "\n",
        "# ===== LOAD ENSEMBLE WEIGHTS =====\n",
        "print('\\n=== Loading Ensemble Weights ===')\n",
        "try:\n",
        "    with open(ENSEMBLE_WEIGHTS_PATH, 'r') as f:\n",
        "        ensemble_info = json.load(f)\n",
        "\n",
        "    weights = ensemble_info['ensemble']['weights']\n",
        "    print(f'✓ Loaded ensemble weights:')\n",
        "    print(f'  seed42:  {weights[\"seed42\"]:.4f}')\n",
        "    print(f'  seed123: {weights[\"seed123\"]:.4f}')\n",
        "    print(f'  seed777: {weights[\"seed777\"]:.4f}')\n",
        "except FileNotFoundError:\n",
        "    print('⚠️ Ensemble weights file not found, using equal weights')\n",
        "    weights = {'seed42': 1/3, 'seed123': 1/3, 'seed777': 1/3}\n",
        "\n",
        "# ===== LOAD TEST DATA =====\n",
        "print('\\n=== Loading Test Data ===')\n",
        "if not os.path.exists(TEST_DATA_PATH):\n",
        "    print(f'❌ Error: Test data not found at {TEST_DATA_PATH}')\n",
        "    print('Please upload test_subtask2a.csv to your Drive folder')\n",
        "else:\n",
        "    test_df = pd.read_csv(TEST_DATA_PATH)\n",
        "    print(f'✓ Loaded test data: {len(test_df)} samples')\n",
        "    \n",
        "    # Preprocess test data\n",
        "    test_df, user_stats_cols, text_feature_cols = preprocess_test_data(test_df)\n",
        "\n",
        "    # ===== CREATE DATASET & DATALOADER =====\n",
        "    print('\\n=== Creating Dataset ===')\n",
        "    tokenizer = AutoTokenizer.from_pretrained('roberta-base')\n",
        "\n",
        "    test_dataset = TestEmotionDataset(\n",
        "        test_df,\n",
        "        tokenizer,\n",
        "        SEQ_LENGTH,\n",
        "        user_stats_cols,\n",
        "        text_feature_cols\n",
        "    )\n",
        "\n",
        "    test_loader = DataLoader(\n",
        "        test_dataset,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        shuffle=False,\n",
        "        num_workers=0\n",
        "    )\n",
        "\n",
        "    # ===== GENERATE PREDICTIONS WITH ENSEMBLE =====\n",
        "    print('\\n=== Generating Predictions with Ensemble ===')\n",
        "\n",
        "    all_predictions = {}\n",
        "\n",
        "    for seed_name, model_path in MODEL_PATHS.items():\n",
        "        print(f'\\nLoading model: {seed_name}')\n",
        "\n",
        "        if not os.path.exists(model_path):\n",
        "            print(f'❌ Error: Model file not found: {model_path}')\n",
        "            continue\n",
        "\n",
        "        # Load checkpoint\n",
        "        checkpoint = torch.load(model_path, map_location=device)\n",
        "        print(f'✓ Loaded checkpoint (CCC: {checkpoint[\"best_ccc\"]:.4f}, Epoch: {checkpoint[\"epoch\"]})')\n",
        "\n",
        "        # Create model\n",
        "        model = FinalEmotionModel(num_users=test_dataset.num_users)\n",
        "        model.load_state_dict(checkpoint['model_state_dict'])\n",
        "        model = model.to(device)\n",
        "        model.eval()\n",
        "\n",
        "        # Generate predictions\n",
        "        valence_preds = []\n",
        "        arousal_preds = []\n",
        "        user_ids = []\n",
        "\n",
        "        print(f'Generating predictions with {seed_name}...')\n",
        "        with torch.no_grad():\n",
        "            for batch in tqdm(test_loader, desc=f'{seed_name} prediction'):\n",
        "                input_ids = batch['input_ids'].to(device)\n",
        "                attention_mask = batch['attention_mask'].to(device)\n",
        "                user_idx = batch['user_idx'].to(device)\n",
        "                temporal_features = batch['temporal_features'].to(device)\n",
        "                user_stats = batch['user_stats'].to(device)\n",
        "                text_features = batch['text_features'].to(device)\n",
        "\n",
        "                valence_pred, arousal_pred = model(\n",
        "                    input_ids, attention_mask, user_idx,\n",
        "                    temporal_features, user_stats, text_features\n",
        "                )\n",
        "\n",
        "                valence_preds.extend(valence_pred.cpu().numpy())\n",
        "                arousal_preds.extend(arousal_pred.cpu().numpy())\n",
        "\n",
        "                if seed_name == 'seed42':  # Only collect user_ids once\n",
        "                    user_ids.extend(batch['user_id'].numpy())\n",
        "\n",
        "        all_predictions[seed_name] = {\n",
        "            'valence': np.array(valence_preds),\n",
        "            'arousal': np.array(arousal_preds)\n",
        "        }\n",
        "\n",
        "        print(f'✓ {seed_name} predictions complete')\n",
        "\n",
        "    # ===== WEIGHTED ENSEMBLE =====\n",
        "    if all_predictions:\n",
        "        print('\\n=== Creating Weighted Ensemble ===')\n",
        "\n",
        "        ensemble_valence = np.zeros_like(all_predictions[list(all_predictions.keys())[0]]['valence'])\n",
        "        ensemble_arousal = np.zeros_like(all_predictions[list(all_predictions.keys())[0]]['arousal'])\n",
        "\n",
        "        total_weight = 0\n",
        "        for seed_name, preds in all_predictions.items():\n",
        "            weight = weights.get(seed_name, 0)\n",
        "            ensemble_valence += weight * preds['valence']\n",
        "            ensemble_arousal += weight * preds['arousal']\n",
        "            total_weight += weight\n",
        "            print(f'{seed_name}: weight {weight:.4f}')\n",
        "        \n",
        "        # Normalize if weights don't sum to 1 (e.g. missing model)\n",
        "        if total_weight > 0:\n",
        "            ensemble_valence /= total_weight\n",
        "            ensemble_arousal /= total_weight\n",
        "\n",
        "        print(f'\\n✓ Ensemble predictions created')\n",
        "\n",
        "        # ===== AGGREGATE BY USER =====\n",
        "        print('\\n=== Aggregating Predictions by User ===')\n",
        "\n",
        "        # Group by user and get last prediction\n",
        "        test_df_with_pred = test_df.copy()\n",
        "        test_df_with_pred['pred_state_change_valence'] = ensemble_valence\n",
        "        test_df_with_pred['pred_state_change_arousal'] = ensemble_arousal\n",
        "\n",
        "        # Sort by timestamp and get last entry per user\n",
        "        final_predictions = test_df_with_pred.sort_values('timestamp').groupby('user_id').last().reset_index()\n",
        "        final_predictions = final_predictions[['user_id', 'pred_state_change_valence', 'pred_state_change_arousal']]\n",
        "\n",
        "        print(f'✓ Final predictions: {len(final_predictions)} users')\n",
        "\n",
        "        # ===== SAVE SUBMISSION FILE =====\n",
        "        output_path = os.path.join(BASE_PATH, 'pred_subtask2a.csv')\n",
        "        final_predictions.to_csv(output_path, index=False)\n",
        "\n",
        "        print('\\n' + '='*80)\n",
        "        print('PREDICTION COMPLETE')\n",
        "        print('='*80)\n",
        "        print(f'✓ Saved predictions to: {output_path}')\n",
        "        print(f'✓ Number of users: {len(final_predictions)}')\n",
        "        print(f'\\nSubmission format:')\n",
        "        print(final_predictions.head(10))\n",
        "    else:\n",
        "        print(\"❌ No predictions generated due to missing models.\")"
      ]
    }
  ]
}
